{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a914377-013f-476d-b030-cd551cef3e87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# QA data checks\n",
    "\n",
    "This Databricks notebook is for checking data > v3.0. Creates counts by POD of each activity type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e15cbaa9-5e86-4e8d-a4c8-b8993c50c437",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import pyspark.sql.functions as F\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nhpy import process_data\n",
    "\n",
    "sys.path.append(spark.conf.get(\"bundle.sourcePath\", \".\"))\n",
    "\n",
    "trusts = [\n",
    "    'RCF',\n",
    "    'RDU',\n",
    "    'RGN',\n",
    "    'RGP',\n",
    "    'RCX',\n",
    "    'RBT',\n",
    "    'RN5',\n",
    "    'RAS',\n",
    "    'RQW',\n",
    "    'RWG',\n",
    "    'R1H',\n",
    "    'RWE',\n",
    "    'RVR',\n",
    "    'RNQ',\n",
    "    'RH5',\n",
    "    'RA9',\n",
    "    'R0A',\n",
    "    'RXC',\n",
    "    'RTX',\n",
    "    'RH8',\n",
    "    'RHW',\n",
    "    'RXN',\n",
    "    'RYJ',\n",
    "    'RX1',\n",
    "    'RGR',\n",
    "    'RD8',\n",
    "    'REF'\n",
    "]\n",
    "\n",
    "year = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e129e44b-599c-4424-a144-a5a0731fb36c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_versions = sorted([f.name.strip(\"/\") for f in dbutils.fs.ls('/Volumes/nhp/model_data/files') if f.isDir() and f.name.startswith(\"v\")])\n",
    "data_versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8eb2396c-e6cf-4a65-89d9-5a62416d11ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Inpatients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20519026-df89-4aa3-9805-d93c9cb1780f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def aggregate_data_ip(data, version):\n",
    "    data[\"beddays\"] = data[\"speldur\"] + 1\n",
    "    return (\n",
    "        data.groupby(\"pod\")\n",
    "        .agg({\"rn\": \"count\", \"beddays\": \"sum\"})\n",
    "        .rename(\n",
    "            columns={\"rn\": f\"{version}_admissions\", \"beddays\": f\"{version}_beddays\"}\n",
    "        )\n",
    "    )\n",
    "\n",
    "data_dict_ip = {}\n",
    "\n",
    "for trust in trusts:\n",
    "    for version in ['dev'] + data_versions[-1:]:\n",
    "        data = pd.read_parquet(f\"/Volumes/nhp/model_data/files/{version}/ip/fyear={year}/dataset={trust}\")\n",
    "        data = process_data.add_pod_to_data_ip(data)\n",
    "        data = aggregate_data_ip(data, version)\n",
    "        if version == 'dev':\n",
    "            df = data.copy()\n",
    "        else:\n",
    "            df = df.merge(data, left_index=True, right_index=True, how='outer').fillna(0).astype(int)\n",
    "    df['trust'] = trust\n",
    "    data_dict_ip[trust] = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f1e6ab8-e17d-4eb0-92c5-5c1bf6a9b678",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Outpatients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f14c7ee-3e12-47e4-b7ec-3e2bf355dcd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def aggregate_data_op(data, version):\n",
    "    return (\n",
    "        data.groupby(\"pod\")\n",
    "        .agg({\"attendances\": \"sum\", \"tele_attendances\": \"sum\"})\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"attendances\": f\"{version}_attendances\",\n",
    "                \"tele_attendances\": f\"{version}_tele_attendances\",\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "data_dict_op = {}\n",
    "\n",
    "for trust in trusts:\n",
    "    for version in [\"dev\"] + data_versions[-1:]:\n",
    "        data = pd.read_parquet(\n",
    "            f\"/Volumes/nhp/model_data/files/{version}/op/fyear={year}/dataset={trust}\"\n",
    "        )\n",
    "        data = process_data.add_pod_to_data_op(data)\n",
    "        data = aggregate_data_op(data, version)\n",
    "        if version == \"dev\":\n",
    "            df = data.copy()\n",
    "        else:\n",
    "            df = (\n",
    "                df.merge(data, left_index=True, right_index=True, how=\"outer\")\n",
    "                .fillna(0)\n",
    "                .astype(int)\n",
    "            )\n",
    "    df[\"trust\"] = trust\n",
    "    data_dict_op[trust] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3f42ffe-402b-42e5-9a34-94e919c5ccb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## A&E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "376855ae-a276-4194-bf88-ac538fd24174",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# aae functions\n",
    "\n",
    "\n",
    "def add_pod_to_data_aae(data):\n",
    "    \"\"\"Adds the POD column to AAE data.\"\"\"\n",
    "    data[\"pod\"] = \"aae_type-\" + data[\"aedepttype\"]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def aggregate_data_aae(data, version):\n",
    "    return (\n",
    "        data.groupby([\"pod\", \"group\"])\n",
    "        .agg({\"arrivals\": \"sum\"})\n",
    "        .rename(columns={\"arrivals\": f\"{version}_arrivals\"})\n",
    "    )\n",
    "\n",
    "data_dict_aae = {}\n",
    "\n",
    "for trust in trusts:\n",
    "    for version in [\"dev\"] + data_versions[-1:]:\n",
    "        data = pd.read_parquet(\n",
    "            f\"/Volumes/nhp/model_data/files/{version}/aae/fyear={year}/dataset={trust}\"\n",
    "        )\n",
    "        data = add_pod_to_data_aae(data)\n",
    "        data = aggregate_data_aae(data, version)\n",
    "        if version == \"dev\":\n",
    "            df = data.copy()\n",
    "        else:\n",
    "            df = (\n",
    "                df.merge(data, left_index=True, right_index=True, how=\"outer\")\n",
    "                .fillna(0)\n",
    "                .astype(int)\n",
    "            )\n",
    "    df[\"trust\"] = trust\n",
    "    data_dict_aae[trust] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfda7a28-5267-40b1-815f-4ef50b50ea67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Mitigators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b7067f0-c351-43c9-a1b6-34c95cfb66de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# IP mitigators\n",
    "\n",
    "ip_mitigators_dict = {}\n",
    "\n",
    "for version in [\"dev\"] + data_versions[-1:]:\n",
    "    aa = pd.read_parquet(\n",
    "            f\"/Volumes/nhp/model_data/files/{version}/ip_activity_avoidance_strategies/fyear={year}\"\n",
    "        ).groupby(\"strategy\").agg({\"rn\": \"count\", \"sample_rate\": \"sum\"}).rename(columns={\"rn\": \"count\"})\n",
    "    ef = pd.read_parquet(\n",
    "            f\"/Volumes/nhp/model_data/files/{version}/ip_efficiencies_strategies/fyear={year}\"\n",
    "        ).groupby(\"strategy\").agg({\"rn\": \"count\", \"sample_rate\": \"sum\"}).rename(columns={\"rn\": \"count\"})\n",
    "    ip_mitigators_dict[version] = pd.concat([aa, ef], axis=0)\n",
    "ip_mitigators = ip_mitigators_dict[\"dev\"].merge(ip_mitigators_dict[data_versions[-1]],  left_index=True, right_index=True, how=\"outer\", suffixes=('_dev', f'_{data_versions[-1]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b129d3f-813f-4c17-a610-be25e6968c89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# OP mitigators\n",
    "\n",
    "op_mitigators_dict = {}\n",
    "\n",
    "for version in [\"dev\"] + data_versions[-1:]:\n",
    "    op = pd.read_parquet(\n",
    "                f\"/Volumes/nhp/model_data/files/{version}/op/fyear={year}\")\n",
    "    op_mitigators = process_data.get_all_op_mitigators(op)\n",
    "    op_mitigators_dict[version] = op_mitigators\n",
    "op_mitigator_names = op_mitigators.columns\n",
    "combined_op_mitigators = op_mitigators_dict[\"dev\"].merge(op_mitigators_dict[data_versions[-1]],  left_index=True, right_index=True, how=\"outer\", suffixes=('_dev', f'_{data_versions[-1]}'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c199744-7442-4978-a645-345e10fe1126",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# AE mitigators\n",
    "\n",
    "aae_mitigators_dict = {}\n",
    "\n",
    "for version in [\"dev\"] + data_versions[-1:]:\n",
    "    aae = pd.read_parquet(\n",
    "                f\"/Volumes/nhp/model_data/files/{version}/aae/fyear={year}\")\n",
    "    aae_mitigators = process_data.get_all_ae_mitigators(aae)\n",
    "    aae_mitigators_dict[version] = aae_mitigators\n",
    "aae_mitigator_names = aae_mitigators.columns\n",
    "combined_aae_mitigators = aae_mitigators_dict[\"dev\"].merge(aae_mitigators_dict[data_versions[-1]],  left_index=True, right_index=True, how=\"outer\", suffixes=('_dev', f'_{data_versions[-1]}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0b6272b-78f8-446e-a9e6-4b9f9a262aa9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Combine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7be184db-fcf4-4552-b0b3-b4a18b59cefe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "today_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "full_df_ip = pd.concat(data_dict_ip.values()).reset_index().set_index(['trust', 'pod'])\n",
    "try:\n",
    "    assert(full_df_ip[\"dev_admissions\"]).equals(full_df_ip[f\"{data_versions[-1]}_admissions\"])\n",
    "    assert(full_df_ip[\"dev_beddays\"]).equals(full_df_ip[f\"{data_versions[-1]}_beddays\"])\n",
    "except:\n",
    "    print(\"Error! Please check file\")\n",
    "full_df_ip.to_csv(f\"{today_date}_QA_ip.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ff1c909-64cf-4c66-9672-33bae206ed69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "full_df_op = pd.concat(data_dict_op.values()).reset_index().set_index(['trust', 'pod'])\n",
    "try:\n",
    "    assert(full_df_op[\"dev_attendances\"]).equals(full_df_op[f\"{data_versions[-1]}_attendances\"])\n",
    "    assert(full_df_op[\"dev_tele_attendances\"]).equals(full_df_op[f\"{data_versions[-1]}_tele_attendances\"])\n",
    "except:\n",
    "    print(\"Error! Please check file\")\n",
    "full_df_op.to_csv(f\"{today_date}_QA_op.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d347a976-a601-4995-8f3d-e3081cbf29b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "full_df_aae = pd.concat(data_dict_aae.values()).reset_index().set_index(['trust', 'pod'])\n",
    "try:\n",
    "    assert(full_df_aae[\"dev_arrivals\"]).equals(full_df_aae[f\"{data_versions[-1]}_arrivals\"])\n",
    "except:\n",
    "    print(\"Error! Please check file\")\n",
    "full_df_aae.to_csv(f\"{today_date}_QA_aae.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9728b7b4-ac4f-4185-aacf-b72c4b23747f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# IP mitigators\n",
    "try:\n",
    "    assert(ip_mitigators[\"count_dev\"]).equals(ip_mitigators[f\"count_{data_versions[-1]}\"])\n",
    "    assert(ip_mitigators[\"sample_rate_dev\"]).equals(ip_mitigators[f\"sample_rate_{data_versions[-1]}\"])\n",
    "except:\n",
    "    print(\"Error! Please check file\")\n",
    "    diffs = ip_mitigators[\"count_dev\"] - ip_mitigators[f\"count_{data_versions[-1]}\"]\n",
    "ip_mitigators.to_csv(f\"{today_date}_QA_ip_mitigators.csv\")\n",
    "diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24f20d82-ea09-4a28-bd1d-f9e06192e24d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# OP mitigators\n",
    "try:\n",
    "    for col in op_mitigator_names:\n",
    "        assert(combined_op_mitigators[f\"{col}_dev\"]).equals(combined_op_mitigators[f\"{col}_{data_versions[-1]}\"])\n",
    "except:\n",
    "    print(\"Error! Please check file\")\n",
    "    print(\"Mitigator with error: {col}\")\n",
    "combined_op_mitigators.sort_index(axis=1).to_csv(f\"{today_date}_QA_op_mitigators.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4469a2f5-00ce-42aa-b0ba-6981a29511b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# AAE mitigators\n",
    "try:\n",
    "    for col in aae_mitigator_names:\n",
    "        assert(combined_aae_mitigators[f\"{col}_dev\"]).equals(combined_aae_mitigators[f\"{col}_{data_versions[-1]}\"])\n",
    "except:\n",
    "    print(\"Error! Please check file\")\n",
    "    print(\"Mitigator with error: {col}\")\n",
    "combined_aae_mitigators.sort_index(axis=1).to_csv(f\"{today_date}_QA_aae_mitigators.csv\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "QA_data_checks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
