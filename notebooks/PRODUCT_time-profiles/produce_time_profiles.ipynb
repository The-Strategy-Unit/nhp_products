{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New time profiles\n",
    "\n",
    "## Background\n",
    "\n",
    "\"Time profiles\" are the term for the year-by-year projection of future activity that is output by the NHP model. \n",
    "\n",
    "To produce time profiles for a particular model scenario, set the path of the `aggregated-model-results` folder on Azure as the variable `path_to_results_file`. The time profiles will be output as CSV and Parquet files saved to the same folder as this notebook.\n",
    "\n",
    "Note that the step_counts currently combines all A&E arrival types (walk-in and ambulance) together, so the time profiles combines both together as well.\n",
    "\n",
    "[The methodology for this notebook is detailed here](https://connect.strategyunitwm.nhs.uk/nhp/project_information/user_guide/glossary.html#time-profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results_folder = #'aggregated-model-results/vX.X/RXX/scenarioname/datetime/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to be in the nhp_products root folder so that we can load nhpy.az\n",
    "%cd ../..\n",
    "\n",
    "from nhpy import az, process_data, process_results\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# Load all environment variables\n",
    "load_dotenv()\n",
    "account_url = os.getenv(\"AZ_STORAGE_EP\")\n",
    "results_container = os.getenv(\"AZ_STORAGE_RESULTS\")\n",
    "\n",
    "results_connection = az.connect_to_container(account_url, results_container)\n",
    "params = az.load_agg_params(results_connection, agg_results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate \"principal\" step count which is the mean of the \"model_runs\" column\n",
    "\n",
    "horizon_year = params['end_year']\n",
    "baseline_year = params['start_year']\n",
    "step_counts = az.load_agg_results(results_connection, agg_results_folder, \"step_counts\")\n",
    "step_counts_df = process_results.convert_results_format(step_counts[step_counts[\"change_factor\"] != \"baseline\"], include_baseline=False).drop(columns = [\"dataset\",\"scenario\",\"app_version\",\"create_datetime\", \"model_runs\"]).set_index(['change_factor', 'activity_type', 'strategy', 'sitetret', 'pod', 'measure'])\n",
    "change_factors = step_counts_df.index.get_level_values(\"change_factor\").unique()\n",
    "step_counts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time profile mappings from params. All change_factors in step_counts need to have a time profile type\n",
    "# Handle cases where time profiles are missing. Could replace with dict.get(\"linear\")?\n",
    "time_profile_mappings = params['time_profile_mappings'].copy()\n",
    "for k,v in time_profile_mappings.items():\n",
    "    if v == 'none':\n",
    "        time_profile_mappings[k] = \"linear\"\n",
    "if 'activity_avoidance' in time_profile_mappings:\n",
    "    for activity_type in time_profile_mappings['activity_avoidance'].keys():\n",
    "        time_profile_mappings['activity_avoidance'][activity_type]['activity_avoidance_interaction_term'] = \"linear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get factors over the years from baseline to horizon year for each change_factor and strategy\n",
    "factor_dict = {}\n",
    "\n",
    "for year in range(1,horizon_year-baseline_year):\n",
    "    time_profiles_dict = process_results.create_time_profiles(horizon_year-baseline_year, year)\n",
    "    for change_factor in change_factors:\n",
    "        # set up blank dict for each change_factor if not already in the factor_dict\n",
    "        if change_factor not in factor_dict.keys():\n",
    "            factor_dict[change_factor] = {}\n",
    "        # get all non-mitigator change factors\n",
    "        if change_factor not in ['activity_avoidance', 'efficiencies']: \n",
    "            # default to linear if not in params. For example model_interaction_term is not in params\n",
    "            time_profile_type = time_profile_mappings.get(change_factor, \"linear\")\n",
    "            factor = process_results.get_time_profiles_factor(time_profile_type, time_profiles_dict, baseline_year)\n",
    "            factor_dict[change_factor][year] = factor\n",
    "        # get mitigator change factors\n",
    "        # bit more complicated because they're nested in the time_profile_mappings\n",
    "        else:\n",
    "            for k,v in time_profile_mappings[change_factor].items():\n",
    "                for strategy, time_profile_type in v.items():\n",
    "                    # Make blank dict if not already in there\n",
    "                    if strategy not in factor_dict.keys():\n",
    "                        factor_dict[strategy] = {}\n",
    "                    factor = process_results.get_time_profiles_factor(time_profile_type, time_profiles_dict, baseline_year)\n",
    "                    factor_dict[strategy][year] = factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tele is just \"convert_to_tele\" in the step counts \n",
    "# but it is divided into different categories e.g. \"convert_to_tele_adult_non-surgical\" and \"convert_to_tele_adult_surgical\" in the time_profile settings\n",
    "# get the mean of the factors across all four categories and use that as the combined \"convert_to_tele\" factor\n",
    "\n",
    "convert_to_tele = {}\n",
    "for k, v in factor_dict.items():\n",
    "    if k.startswith('convert_to_tele'):\n",
    "        for year, factor in v.items():\n",
    "            if year not in convert_to_tele:\n",
    "                convert_to_tele[year] = []\n",
    "            convert_to_tele[year].append(factor)\n",
    "for k, v in convert_to_tele.items():\n",
    "    convert_to_tele[k] = np.mean(v)\n",
    "factor_dict['convert_to_tele'] = convert_to_tele\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df to work with\n",
    "\n",
    "working_step_counts_df = step_counts_df.rename(columns = {\"mean\": horizon_year}).sort_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get actual values of change for each param and year\n",
    "\n",
    "# Non mitigator ones first\n",
    "for change_factor in change_factors:\n",
    "    if change_factor not in ['activity_avoidance', 'efficiencies']: \n",
    "        indices = working_step_counts_df.loc[(change_factor, slice(None), slice(None), slice(None), slice(None), slice(None)), :].index\n",
    "        # Iterate through all the change_factors named in the step_counts, get the factor for the specific year/param and multiply by baseline year\n",
    "        for i in indices:\n",
    "            for year, factor in factor_dict[change_factor].items():\n",
    "                working_step_counts_df.loc[i, baseline_year + year] = working_step_counts_df.loc[i, horizon_year] * factor\n",
    "# Mitigators\n",
    "for strategy in working_step_counts_df.index.get_level_values('strategy').unique():\n",
    "    if strategy != '-':\n",
    "        indices = working_step_counts_df.loc[(slice(None), slice(None), strategy, slice(None), slice(None), slice(None)), :].index\n",
    "        # Iterate through all the mitigator strategies named in the step_counts, get the factor for the specific year/param and multiply by baseline year\n",
    "        for i in indices:\n",
    "            for year, factor in factor_dict[strategy].items():\n",
    "                working_step_counts_df.loc[i, baseline_year + year] = working_step_counts_df.loc[i, horizon_year] * factor\n",
    "working_step_counts_df = working_step_counts_df.sort_index(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time_profiles_df with the values for the baseline year as template\n",
    "\n",
    "time_profiles_df = (\n",
    "    step_counts[\n",
    "        (step_counts[\"change_factor\"] == \"baseline\") & (step_counts[\"model_run\"] == 1)\n",
    "    ]\n",
    "    .groupby([\"sitetret\", \"pod\", \"measure\"])[[\"value\"]]\n",
    "    .sum()\n",
    "    .rename(columns={\"value\": baseline_year})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align indices of step_counts_df with the template df\n",
    "\n",
    "step_counts_grouped = working_step_counts_df.reset_index().groupby(['sitetret', 'pod', 'measure']).sum(True).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all PODs into the time_profiles_df, even if they didn't exist in the original baseline\n",
    "missing_indices = step_counts_grouped.index.difference(time_profiles_df.index)\n",
    "if len(missing_indices) > 0:\n",
    "    filler_df = pd.DataFrame(\n",
    "        {baseline_year: 0},\n",
    "        index=missing_indices\n",
    "    )\n",
    "    time_profiles_df = pd.concat([time_profiles_df, filler_df])\n",
    "time_profiles_df = time_profiles_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference between horizon year and baseline year\n",
    "years = step_counts_grouped.columns\n",
    "for i in time_profiles_df.index:\n",
    "    time_profiles_df.loc[i, years] = time_profiles_df.loc[i, baseline_year] + step_counts_grouped.loc[i]\n",
    "time_profiles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_profiles_df.to_parquet(f'{params[\"scenario\"]}_timeprofile.parquet')\n",
    "time_profiles_df.to_csv(f'{params[\"scenario\"]}_timeprofile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA: check if numbers align \n",
    "default_df = process_results.convert_results_format(az.load_agg_results(results_connection, agg_results_folder, \"default\"))\n",
    "# Account for differences between step_counts measures and default measures\n",
    "default_df['measure'] = default_df['measure'].apply(lambda x: \"arrivals\" if x in [\"ambulance\", \"walk-in\"] else x)\n",
    "default_df = default_df[default_df[\"measure\"] != \"procedures\"]\n",
    "default_df = default_df.groupby([\"sitetret\", \"pod\", \"measure\"])[[\"mean\"]].sum().loc[time_profiles_df.index]\n",
    "# Script needs to print this out for checking \n",
    "default_df[\"mean\"].compare(time_profiles_df[horizon_year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"{len(default_df[\"mean\"].compare(time_profiles_df[horizon_year]))} rows different from total of {len(time_profiles_df)} rows\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "site_level_mitigators",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
