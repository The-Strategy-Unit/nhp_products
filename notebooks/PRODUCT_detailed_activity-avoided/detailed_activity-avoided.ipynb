{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed results\n",
    "\n",
    "This notebook is for producing detailed activity avoided for model >= 3.1 - with sex and birth episodes flag in inpatients.\n",
    "\n",
    "Assumes you have already authenticated via az. Outputs into a `data/` folder the avoided activity for inpatients with HRG, an indicator if LOS is 0 or >0, and pod.\n",
    "\n",
    "Also assumes that the scenario has already been run with full_model_results = True\n",
    "\n",
    "This notebook uses the new format of the aggregated results parquet files rather than the old massive JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results_folder = \"aggregated-model-results/vX.X/RXX/scenarioname/datetime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to be in the nhp_products root folder so that we can load nhpy.az\n",
    "%cd ../..\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from nhpy import az, process_data\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "load_dotenv()\n",
    "account_url = os.getenv(\"AZ_STORAGE_EP\")\n",
    "results_container = os.getenv(\"AZ_STORAGE_RESULTS\")\n",
    "data_container = os.getenv(\"AZ_STORAGE_DATA\")\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "results_connection = az.connect_to_container(account_url, results_container)\n",
    "data_connection = az.connect_to_container(account_url, data_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables\n",
    "\n",
    "params = az.load_agg_params(results_connection, agg_results_folder)\n",
    "\n",
    "model_version = agg_results_folder.split(\"/\")[1]\n",
    "dataset = agg_results_folder.split(\"/\")[2]\n",
    "scenario_name = agg_results_folder.split(\"/\")[3]\n",
    "create_datetime = agg_results_folder.split(\"/\")[4]\n",
    "baseline_year = params[\"start_year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch model version for loading the data\n",
    "# Results folder name truncated, e.g. v3.0 - does not show the patch version. But data stores in format v3.0.1\n",
    "model_version_data = az.find_latest_version(data_connection, model_version)\n",
    "print(f\"Using data: {model_version_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Data folder if it doesn't exist\n",
    "\n",
    "if not os.path.exists(\"notebooks/PRODUCT_detailed_activity-avoided/data/\"):\n",
    "    os.makedirs(\"notebooks/PRODUCT_detailed_activity-avoided/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start processing\n",
    "\n",
    "original_df = az.load_data_file(\n",
    "    data_connection, model_version_data, dataset, \"ip\", baseline_year\n",
    ")\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_runs = {}\n",
    "for run in range(1, 257):\n",
    "    df = az.load_model_run_results_file(\n",
    "        results_connection,\n",
    "        model_version,\n",
    "        dataset,\n",
    "        scenario_name,\n",
    "        create_datetime,\n",
    "        \"ip_avoided\",\n",
    "        run,\n",
    "    )\n",
    "    # We want to use the speldur and classpat from the results, not from the original df\n",
    "    merged = (\n",
    "        original_df.copy()\n",
    "        .drop(columns=[\"speldur\", \"classpat\"])\n",
    "        .merge(df, on=\"rn\", how=\"inner\")\n",
    "    )\n",
    "    results_dict = process_data.process_ip_activity_avoided(merged).to_dict()\n",
    "    for k, v in results_dict[\"value\"].items():\n",
    "        if k not in model_runs.keys():\n",
    "            model_runs[k] = []\n",
    "        model_runs[k].append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_runs_df = process_data.process_model_runs_dict(\n",
    "    model_runs, columns=[\"pod\", \"los_group\", \"sushrg\", \"measure\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_runs_df.to_csv(\n",
    "    f\"notebooks/PRODUCT_detailed_activity-avoided/data/{scenario_name}_ip_activity_avoided_hrg.csv\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nhp_products",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
